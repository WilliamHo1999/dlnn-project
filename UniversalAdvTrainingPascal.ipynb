{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa83dd38-e7ae-4fd8-a257-6dd5bd33fba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import PIL.Image\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "\n",
    "from src.data.PascalVOC import dataset_voc, prepare_dataloaders_pascal_voc\n",
    "from src.attacks.attacks import FastGradientSign, ProjectedGradientDescent, UniversalAttack\n",
    "from src.training.Trainer import Trainer\n",
    "from src.optim.scheduler import CustomScheduler\n",
    "\n",
    "\n",
    "def seed_everything(seed_value=4995):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)\n",
    "\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def load_model(num_classes = 20, model_path = None, to_cuda = True):\n",
    "    if not model_path:\n",
    "        model = torchvision.models.resnet18(pretrained = True)\n",
    "        input_feat = model.fc.in_features\n",
    "        \n",
    "        model.fc = nn.Linear(input_feat, num_classes)\n",
    "        model.fc.reset_parameters()\n",
    "        loaded_state_dict = False\n",
    "    \n",
    "    else:\n",
    "        print(\"Loaded\", model_path)\n",
    "        model = torchvision.models.resnet18()\n",
    "        input_feat = model.fc.in_features\n",
    "        model.fc = nn.Linear(input_feat, num_classes)\n",
    "        loaded_model = torch.load(model_path)\n",
    "        model.load_state_dict(loaded_model['model_state_dict'])\n",
    "        loaded_state_dict = True\n",
    "        \n",
    "    if to_cuda:\n",
    "        model = model.to('cuda')\n",
    "        \n",
    "    return model, loaded_state_dict\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31c0aa79-06de-4147-a1ed-54e34011eca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded models/pascal_voc_resnet_fine_tuned.pt\n",
      "Current Epoch: 0\n",
      "Train Loop:\n",
      "Batch: 0 of 90. Loss: 0.2021379917860031. Mean so far: 0.2021379917860031. Mean of 100: 0.2021379917860031\n",
      "Batch: 10 of 90. Loss: 0.16344387829303741. Mean so far: 0.16806463626298038. Mean of 100: 0.16806463626298038\n",
      "Batch: 20 of 90. Loss: 0.1381864994764328. Mean so far: 0.15990073340279715. Mean of 100: 0.15990073340279715\n",
      "Batch: 30 of 90. Loss: 0.15097014605998993. Mean so far: 0.1568525955080986. Mean of 100: 0.1568525955080986\n",
      "Batch: 40 of 90. Loss: 0.1724778711795807. Mean so far: 0.1563943608141527. Mean of 100: 0.1563943608141527\n",
      "Batch: 50 of 90. Loss: 0.14087842404842377. Mean so far: 0.1534918800872915. Mean of 100: 0.1534918800872915\n",
      "Batch: 60 of 90. Loss: 0.1366935819387436. Mean so far: 0.15174675818349495. Mean of 100: 0.15174675818349495\n",
      "Batch: 70 of 90. Loss: 0.1569652408361435. Mean so far: 0.15102839994598444. Mean of 100: 0.15102839994598444\n",
      "Batch: 80 of 90. Loss: 0.1324392408132553. Mean so far: 0.14963125547877065. Mean of 100: 0.14963125547877065\n",
      "Train loss: 0.14997611732946503. Train measure: 0.5429645714075012\n",
      "Train loop took 41.37263083457947\n",
      "Val Loop:\n",
      "Batch: 0 of 91. Loss: 0.13887451589107513. Mean so far: 0.13887451589107513. Mean of 100: 0.13887451589107513\n",
      "Batch: 10 of 91. Loss: 0.12264972180128098. Mean so far: 0.1678602390668609. Mean of 100: 0.1678602390668609\n",
      "Batch: 20 of 91. Loss: 0.20598740875720978. Mean so far: 0.15469877067066373. Mean of 100: 0.15469877067066373\n",
      "Batch: 30 of 91. Loss: 0.176592618227005. Mean so far: 0.1682809466315854. Mean of 100: 0.1682809466315854\n",
      "Batch: 40 of 91. Loss: 0.13412168622016907. Mean so far: 0.16017333163720807. Mean of 100: 0.16017333163720807\n",
      "Batch: 50 of 91. Loss: 0.11279070377349854. Mean so far: 0.1705345919027048. Mean of 100: 0.1705345919027048\n",
      "Batch: 60 of 91. Loss: 0.14735639095306396. Mean so far: 0.16865283043169585. Mean of 100: 0.16865283043169585\n",
      "Batch: 70 of 91. Loss: 0.07613638788461685. Mean so far: 0.16602341673323806. Mean of 100: 0.16602341673323806\n",
      "Batch: 80 of 91. Loss: 0.12049799412488937. Mean so far: 0.16010134906312565. Mean of 100: 0.16010134906312565\n",
      "Batch: 90 of 91. Loss: 0.08222825825214386. Mean so far: 0.15536369219586088. Mean of 100: 0.15536369219586088\n",
      "Validation loss: 0.15536369219586088. Val measure: 0.5448293067540735\n",
      "Validation loop took 39.08536410331726\n",
      "Current Epoch: 0\n",
      "Eval  Model:  pascal_voc_uni_adv_trained . MAPE:  0.5448293067540735 . Avg loss: 0.15536369219586088\n",
      "Train Model:  pascal_voc_uni_adv_trained . MAPE 0.5429645714075012 Avg loss: 0.14997611732946503\n",
      "Current MAPE:  0.5448293067540735 0.15536369219586088 at epoch 0\n",
      "AP of aeroplane    : 0.7858509829630528\n",
      "AP of bicycle      : 0.5702575796846175\n",
      "AP of bird         : 0.5628570443534442\n",
      "AP of boat         : 0.5437552946039194\n",
      "AP of bottle       : 0.3185718576918279\n",
      "AP of bus          : 0.8051990454810897\n",
      "AP of car          : 0.6072500820916219\n",
      "AP of cat          : 0.6169749424041713\n",
      "AP of chair        : 0.49230959413258635\n",
      "AP of cow          : 0.32306717661427525\n",
      "AP of diningtable  : 0.3886495102619231\n",
      "AP of dog          : 0.5328209349400508\n",
      "AP of horse        : 0.42444516925883147\n",
      "AP of motorbike    : 0.6857718886650233\n",
      "AP of person       : 0.8073698055979448\n",
      "AP of pottedplant  : 0.3032461035715057\n",
      "AP of sheep        : 0.4857874382872878\n",
      "AP of sofa         : 0.27979020771058094\n",
      "AP of train        : 0.7108437691216232\n",
      "AP of tvmonitor    : 0.651767707646093\n",
      "Current Epoch: 1\n",
      "Train Loop:\n",
      "Batch: 0 of 90. Loss: 0.12398536503314972. Mean so far: 0.12398536503314972. Mean of 100: 0.12398536503314972\n",
      "Batch: 10 of 90. Loss: 0.15132179856300354. Mean so far: 0.13728183169256558. Mean of 100: 0.13728183169256558\n",
      "Batch: 20 of 90. Loss: 0.1339634358882904. Mean so far: 0.1363863746325175. Mean of 100: 0.1363863746325175\n",
      "Batch: 30 of 90. Loss: 0.12960471212863922. Mean so far: 0.13444336744085436. Mean of 100: 0.13444336744085436\n",
      "Batch: 40 of 90. Loss: 0.1136176809668541. Mean so far: 0.13369350644146524. Mean of 100: 0.13369350644146524\n",
      "Batch: 50 of 90. Loss: 0.11527078598737717. Mean so far: 0.1340099844862433. Mean of 100: 0.1340099844862433\n",
      "Batch: 60 of 90. Loss: 0.12166384607553482. Mean so far: 0.13387469031283114. Mean of 100: 0.13387469031283114\n",
      "Batch: 70 of 90. Loss: 0.1451658457517624. Mean so far: 0.1346376090192459. Mean of 100: 0.1346376090192459\n",
      "Batch: 80 of 90. Loss: 0.13789956271648407. Mean so far: 0.13480072210968277. Mean of 100: 0.13480072210968277\n",
      "Train loss: 0.13513029052151573. Train measure: 0.6099803447455746\n",
      "Train loop took 41.64728498458862\n",
      "Val Loop:\n",
      "Batch: 0 of 91. Loss: 0.180241659283638. Mean so far: 0.180241659283638. Mean of 100: 0.180241659283638\n",
      "Batch: 10 of 91. Loss: 0.1897069662809372. Mean so far: 0.17648908766833218. Mean of 100: 0.17648908766833218\n",
      "Batch: 20 of 91. Loss: 0.13136640191078186. Mean so far: 0.1708287617989949. Mean of 100: 0.1708287617989949\n",
      "Batch: 30 of 91. Loss: 0.19143624603748322. Mean so far: 0.16580190245182283. Mean of 100: 0.16580190245182283\n",
      "Batch: 40 of 91. Loss: 0.15360502898693085. Mean so far: 0.15971412655056977. Mean of 100: 0.15971412655056977\n",
      "Batch: 50 of 91. Loss: 0.15928874909877777. Mean so far: 0.16592570102097942. Mean of 100: 0.16592570102097942\n",
      "Batch: 60 of 91. Loss: 0.14575541019439697. Mean so far: 0.16546704668979176. Mean of 100: 0.16546704668979176\n",
      "Batch: 70 of 91. Loss: 0.09165453910827637. Mean so far: 0.16551968392351984. Mean of 100: 0.16551968392351984\n",
      "Batch: 80 of 91. Loss: 0.13128304481506348. Mean so far: 0.16122652019983458. Mean of 100: 0.16122652019983458\n",
      "Batch: 90 of 91. Loss: 0.09790267795324326. Mean so far: 0.16021263296460056. Mean of 100: 0.16021263296460056\n",
      "Validation loss: 0.16021263296460056. Val measure: 0.5500268671104631\n",
      "Validation loop took 39.115598917007446\n",
      "Current Epoch: 1\n",
      "Eval  Model:  pascal_voc_uni_adv_trained . MAPE:  0.5500268671104631 . Avg loss: 0.16021263296460056\n",
      "Train Model:  pascal_voc_uni_adv_trained . MAPE 0.6099803447455746 Avg loss: 0.13513029052151573\n",
      "Current MAPE:  0.5500268671104631 0.16021263296460056 at epoch 1\n",
      "AP of aeroplane    : 0.7446457593182355\n",
      "AP of bicycle      : 0.5299880387874187\n",
      "AP of bird         : 0.5975223171326974\n",
      "AP of boat         : 0.5645995587945508\n",
      "AP of bottle       : 0.2858683093520595\n",
      "AP of bus          : 0.776115508166679\n",
      "AP of car          : 0.5885208424340284\n",
      "AP of cat          : 0.6472439037369282\n",
      "AP of chair        : 0.5186172295532797\n",
      "AP of cow          : 0.39990644653965024\n",
      "AP of diningtable  : 0.3925703666339269\n",
      "AP of dog          : 0.5351770774285401\n",
      "AP of horse        : 0.45486587983370946\n",
      "AP of motorbike    : 0.6125026484801572\n",
      "AP of person       : 0.8533558324108811\n",
      "AP of pottedplant  : 0.34213111287184556\n",
      "AP of sheep        : 0.417911434784688\n",
      "AP of sofa         : 0.3282133968710195\n",
      "AP of train        : 0.7356264847046963\n",
      "AP of tvmonitor    : 0.6751551943742721\n",
      "Current Epoch: 2\n",
      "Train Loop:\n",
      "Batch: 0 of 90. Loss: 0.14123134315013885. Mean so far: 0.14123134315013885. Mean of 100: 0.14123134315013885\n",
      "Batch: 10 of 90. Loss: 0.13136088848114014. Mean so far: 0.13107268850911746. Mean of 100: 0.13107268850911746\n",
      "Batch: 20 of 90. Loss: 0.11772336810827255. Mean so far: 0.13123757463125957. Mean of 100: 0.13123757463125957\n",
      "Batch: 30 of 90. Loss: 0.14084473252296448. Mean so far: 0.13162570807241625. Mean of 100: 0.13162570807241625\n",
      "Batch: 40 of 90. Loss: 0.12403569370508194. Mean so far: 0.1315654992330365. Mean of 100: 0.1315654992330365\n",
      "Batch: 50 of 90. Loss: 0.12537871301174164. Mean so far: 0.13173450719492108. Mean of 100: 0.13173450719492108\n",
      "Batch: 60 of 90. Loss: 0.1290903240442276. Mean so far: 0.1326327877210789. Mean of 100: 0.1326327877210789\n",
      "Batch: 70 of 90. Loss: 0.10085637867450714. Mean so far: 0.1320252012408955. Mean of 100: 0.1320252012408955\n",
      "Batch: 80 of 90. Loss: 0.13052459061145782. Mean so far: 0.1327223366609326. Mean of 100: 0.1327223366609326\n",
      "Train loss: 0.13316912510328824. Train measure: 0.619788005079611\n",
      "Train loop took 41.36132264137268\n",
      "Val Loop:\n",
      "Batch: 0 of 91. Loss: 0.16068755090236664. Mean so far: 0.16068755090236664. Mean of 100: 0.16068755090236664\n",
      "Batch: 10 of 91. Loss: 0.13861411809921265. Mean so far: 0.16213203424757178. Mean of 100: 0.16213203424757178\n",
      "Batch: 20 of 91. Loss: 0.21507816016674042. Mean so far: 0.1536998464947655. Mean of 100: 0.1536998464947655\n",
      "Batch: 30 of 91. Loss: 0.16507184505462646. Mean so far: 0.16318413158578257. Mean of 100: 0.16318413158578257\n",
      "Batch: 40 of 91. Loss: 0.1940479427576065. Mean so far: 0.16347973466646382. Mean of 100: 0.16347973466646382\n",
      "Batch: 50 of 91. Loss: 0.1983940452337265. Mean so far: 0.17458652734172111. Mean of 100: 0.17458652734172111\n",
      "Batch: 60 of 91. Loss: 0.12897633016109467. Mean so far: 0.17133579317663536. Mean of 100: 0.17133579317663536\n",
      "Batch: 70 of 91. Loss: 0.0747351199388504. Mean so far: 0.163543658357271. Mean of 100: 0.163543658357271\n",
      "Batch: 80 of 91. Loss: 0.10914953052997589. Mean so far: 0.15656259573168224. Mean of 100: 0.15656259573168224\n",
      "Batch: 90 of 91. Loss: 0.09313052147626877. Mean so far: 0.15204154245637275. Mean of 100: 0.15204154245637275\n",
      "Validation loss: 0.15204154245637275. Val measure: 0.5561857814024375\n",
      "Validation loop took 38.919987201690674\n",
      "Current Epoch: 2\n",
      "Eval  Model:  pascal_voc_uni_adv_trained . MAPE:  0.5561857814024375 . Avg loss: 0.15204154245637275\n",
      "Train Model:  pascal_voc_uni_adv_trained . MAPE 0.619788005079611 Avg loss: 0.13316912510328824\n",
      "Current MAPE:  0.5561857814024375 0.15204154245637275 at epoch 2\n",
      "AP of aeroplane    : 0.8000508107532887\n",
      "AP of bicycle      : 0.5755526722279425\n",
      "AP of bird         : 0.5983423376715432\n",
      "AP of boat         : 0.6089889472441619\n",
      "AP of bottle       : 0.3246908485465806\n",
      "AP of bus          : 0.8181023147125852\n",
      "AP of car          : 0.5918145460929312\n",
      "AP of cat          : 0.5869254042429353\n",
      "AP of chair        : 0.4978642410493175\n",
      "AP of cow          : 0.25922343133536885\n",
      "AP of diningtable  : 0.4215251874976177\n",
      "AP of dog          : 0.521945262033648\n",
      "AP of horse        : 0.4500335497326298\n",
      "AP of motorbike    : 0.6692226451693376\n",
      "AP of person       : 0.841278277444213\n",
      "AP of pottedplant  : 0.3654984696473887\n",
      "AP of sheep        : 0.4683824530654095\n",
      "AP of sofa         : 0.3441460897034717\n",
      "AP of train        : 0.7405099471132295\n",
      "AP of tvmonitor    : 0.6396181927651499\n",
      "Current Epoch: 3\n",
      "Train Loop:\n",
      "Batch: 0 of 90. Loss: 0.14323030412197113. Mean so far: 0.14323030412197113. Mean of 100: 0.14323030412197113\n",
      "Batch: 10 of 90. Loss: 0.11202645301818848. Mean so far: 0.12506212023171512. Mean of 100: 0.12506212023171512\n",
      "Batch: 20 of 90. Loss: 0.12087585777044296. Mean so far: 0.12474619348843892. Mean of 100: 0.12474619348843892\n",
      "Batch: 30 of 90. Loss: 0.11559803783893585. Mean so far: 0.12649205254931603. Mean of 100: 0.12649205254931603\n",
      "Batch: 40 of 90. Loss: 0.14491544663906097. Mean so far: 0.12852263159868194. Mean of 100: 0.12852263159868194\n",
      "Batch: 50 of 90. Loss: 0.129265695810318. Mean so far: 0.12850354027514363. Mean of 100: 0.12850354027514363\n",
      "Batch: 60 of 90. Loss: 0.12792132794857025. Mean so far: 0.12911930497063964. Mean of 100: 0.12911930497063964\n",
      "Batch: 70 of 90. Loss: 0.13763517141342163. Mean so far: 0.12975296273197925. Mean of 100: 0.12975296273197925\n",
      "Batch: 80 of 90. Loss: 0.13998810946941376. Mean so far: 0.13102674594631902. Mean of 100: 0.13102674594631902\n",
      "Train loss: 0.13202806587020557. Train measure: 0.6235829103290673\n",
      "Train loop took 41.291682958602905\n",
      "Val Loop:\n",
      "Batch: 0 of 91. Loss: 0.12328553199768066. Mean so far: 0.12328553199768066. Mean of 100: 0.12328553199768066\n",
      "Batch: 10 of 91. Loss: 0.20875973999500275. Mean so far: 0.1529452699151906. Mean of 100: 0.1529452699151906\n",
      "Batch: 20 of 91. Loss: 0.17525498569011688. Mean so far: 0.1695616610703014. Mean of 100: 0.1695616610703014\n",
      "Batch: 30 of 91. Loss: 0.18718644976615906. Mean so far: 0.172166001171835. Mean of 100: 0.172166001171835\n",
      "Batch: 40 of 91. Loss: 0.16255299746990204. Mean so far: 0.16570054376270713. Mean of 100: 0.16570054376270713\n",
      "Batch: 50 of 91. Loss: 0.18155960738658905. Mean so far: 0.16979864984750748. Mean of 100: 0.16979864984750748\n",
      "Batch: 60 of 91. Loss: 0.13060800731182098. Mean so far: 0.1657946738796156. Mean of 100: 0.1657946738796156\n",
      "Batch: 70 of 91. Loss: 0.06716875731945038. Mean so far: 0.15998626762712506. Mean of 100: 0.15998626762712506\n",
      "Batch: 80 of 91. Loss: 0.1039946898818016. Mean so far: 0.15334918938669156. Mean of 100: 0.15334918938669156\n",
      "Batch: 90 of 91. Loss: 0.11666709184646606. Mean so far: 0.15197248503074542. Mean of 100: 0.15197248503074542\n",
      "Validation loss: 0.15197248503074542. Val measure: 0.5383881973463931\n",
      "Validation loop took 39.07179498672485\n",
      "Current Epoch: 3\n",
      "Eval  Model:  pascal_voc_uni_adv_trained . MAPE:  0.5383881973463931 . Avg loss: 0.15197248503074542\n",
      "Train Model:  pascal_voc_uni_adv_trained . MAPE 0.6235829103290673 Avg loss: 0.13202806587020557\n",
      "Current MAPE:  0.5561857814024375 0.15204154245637275 at epoch 2\n",
      "AP of aeroplane    : 0.7689602690494536\n",
      "AP of bicycle      : 0.563344232399261\n",
      "AP of bird         : 0.5454699376292258\n",
      "AP of boat         : 0.5371796108058973\n",
      "AP of bottle       : 0.3058244618321466\n",
      "AP of bus          : 0.782334050462718\n",
      "AP of car          : 0.5717258116836355\n",
      "AP of cat          : 0.6393910429949599\n",
      "AP of chair        : 0.47395459422775515\n",
      "AP of cow          : 0.26121452201077044\n",
      "AP of diningtable  : 0.37370645144892245\n",
      "AP of dog          : 0.5311710670244537\n",
      "AP of horse        : 0.4425847057676721\n",
      "AP of motorbike    : 0.633526345217473\n",
      "AP of person       : 0.8607492572225262\n",
      "AP of pottedplant  : 0.32837752020166616\n",
      "AP of sheep        : 0.45876703386508527\n",
      "AP of sofa         : 0.34421311630632145\n",
      "AP of train        : 0.6983298734046668\n",
      "AP of tvmonitor    : 0.6469400433732505\n",
      "Current Epoch: 4\n",
      "Train Loop:\n",
      "Batch: 0 of 90. Loss: 0.1334238350391388. Mean so far: 0.1334238350391388. Mean of 100: 0.1334238350391388\n",
      "Batch: 10 of 90. Loss: 0.12717542052268982. Mean so far: 0.12957563996315002. Mean of 100: 0.12957563996315002\n",
      "Batch: 20 of 90. Loss: 0.12385284900665283. Mean so far: 0.12394393341881889. Mean of 100: 0.12394393341881889\n",
      "Batch: 30 of 90. Loss: 0.11867933720350266. Mean so far: 0.12171727707309107. Mean of 100: 0.12171727707309107\n",
      "Batch: 40 of 90. Loss: 0.09838572144508362. Mean so far: 0.12060338713046981. Mean of 100: 0.12060338713046981\n",
      "Batch: 50 of 90. Loss: 0.10090422630310059. Mean so far: 0.11883880212610844. Mean of 100: 0.11883880212610844\n",
      "Batch: 60 of 90. Loss: 0.1063905581831932. Mean so far: 0.11827841278959493. Mean of 100: 0.11827841278959493\n",
      "Batch: 70 of 90. Loss: 0.11594369262456894. Mean so far: 0.11708879397368767. Mean of 100: 0.11708879397368767\n",
      "Batch: 80 of 90. Loss: 0.11173120886087418. Mean so far: 0.116154257805995. Mean of 100: 0.116154257805995\n",
      "Train loss: 0.11550138153963618. Train measure: 0.7128194899529434\n",
      "Train loop took 41.44917297363281\n",
      "Val Loop:\n",
      "Batch: 0 of 91. Loss: 0.11600551754236221. Mean so far: 0.11600551754236221. Mean of 100: 0.11600551754236221\n",
      "Batch: 10 of 91. Loss: 0.12247961014509201. Mean so far: 0.12737873941659927. Mean of 100: 0.12737873941659927\n",
      "Batch: 20 of 91. Loss: 0.1647862195968628. Mean so far: 0.12741775172097342. Mean of 100: 0.12741775172097342\n",
      "Batch: 30 of 91. Loss: 0.1709648221731186. Mean so far: 0.14017317948802824. Mean of 100: 0.14017317948802824\n",
      "Batch: 40 of 91. Loss: 0.13647706806659698. Mean so far: 0.13607017477838004. Mean of 100: 0.13607017477838004\n",
      "Batch: 50 of 91. Loss: 0.15968553721904755. Mean so far: 0.14341386056998195. Mean of 100: 0.14341386056998195\n",
      "Batch: 60 of 91. Loss: 0.13392876088619232. Mean so far: 0.14318788344742822. Mean of 100: 0.14318788344742822\n",
      "Batch: 70 of 91. Loss: 0.061099469661712646. Mean so far: 0.1389653387833649. Mean of 100: 0.1389653387833649\n",
      "Batch: 80 of 91. Loss: 0.09450255334377289. Mean so far: 0.1340726591002794. Mean of 100: 0.1340726591002794\n",
      "Batch: 90 of 91. Loss: 0.10245751589536667. Mean so far: 0.1321749706025962. Mean of 100: 0.1321749706025962\n",
      "Validation loss: 0.1321749706025962. Val measure: 0.6131131088893695\n",
      "Validation loop took 39.12446713447571\n",
      "Current Epoch: 4\n",
      "Eval  Model:  pascal_voc_uni_adv_trained . MAPE:  0.6131131088893695 . Avg loss: 0.1321749706025962\n",
      "Train Model:  pascal_voc_uni_adv_trained . MAPE 0.7128194899529434 Avg loss: 0.11550138153963618\n",
      "Current MAPE:  0.6131131088893695 0.1321749706025962 at epoch 4\n",
      "AP of aeroplane    : 0.8385549490984364\n",
      "AP of bicycle      : 0.6489453012221529\n",
      "AP of bird         : 0.665674704889778\n",
      "AP of boat         : 0.6455214597479764\n",
      "AP of bottle       : 0.3564281227137442\n",
      "AP of bus          : 0.8452657471710252\n",
      "AP of car          : 0.6479182939610014\n",
      "AP of cat          : 0.6921172562322343\n",
      "AP of chair        : 0.5343048540612807\n",
      "AP of cow          : 0.3942329768163164\n",
      "AP of diningtable  : 0.4348690972631523\n",
      "AP of dog          : 0.58665304458382\n",
      "AP of horse        : 0.5374360288633653\n",
      "AP of motorbike    : 0.7461890499757106\n",
      "AP of person       : 0.879909558441924\n",
      "AP of pottedplant  : 0.4076229648365307\n",
      "AP of sheep        : 0.5769265441695949\n",
      "AP of sofa         : 0.37914804167964455\n",
      "AP of train        : 0.7814654422557449\n",
      "AP of tvmonitor    : 0.6630787398039543\n",
      "Current Epoch: 5\n",
      "Train Loop:\n",
      "Batch: 0 of 90. Loss: 0.09841972589492798. Mean so far: 0.09841972589492798. Mean of 100: 0.09841972589492798\n",
      "Batch: 10 of 90. Loss: 0.09956873208284378. Mean so far: 0.1127347858114676. Mean of 100: 0.1127347858114676\n",
      "Batch: 20 of 90. Loss: 0.10607676953077316. Mean so far: 0.1099383533000946. Mean of 100: 0.1099383533000946\n",
      "Batch: 30 of 90. Loss: 0.08816829323768616. Mean so far: 0.10700783638223525. Mean of 100: 0.10700783638223525\n",
      "Batch: 40 of 90. Loss: 0.10097723454236984. Mean so far: 0.10690315649276827. Mean of 100: 0.10690315649276827\n",
      "Batch: 50 of 90. Loss: 0.10022290050983429. Mean so far: 0.10654061112333746. Mean of 100: 0.10654061112333746\n",
      "Batch: 60 of 90. Loss: 0.09772247076034546. Mean so far: 0.10578028967634576. Mean of 100: 0.10578028967634576\n",
      "Batch: 70 of 90. Loss: 0.09829510003328323. Mean so far: 0.10523968032548126. Mean of 100: 0.10523968032548126\n",
      "Batch: 80 of 90. Loss: 0.10702407360076904. Mean so far: 0.10503934351382432. Mean of 100: 0.10503934351382432\n",
      "Train loss: 0.10491702374484804. Train measure: 0.7600644825113345\n",
      "Train loop took 41.61217927932739\n",
      "Val Loop:\n",
      "Batch: 0 of 91. Loss: 0.10010217875242233. Mean so far: 0.10010217875242233. Mean of 100: 0.10010217875242233\n",
      "Batch: 10 of 91. Loss: 0.12561571598052979. Mean so far: 0.11990064721215855. Mean of 100: 0.11990064721215855\n",
      "Batch: 20 of 91. Loss: 0.16317979991436005. Mean so far: 0.12324021259943645. Mean of 100: 0.12324021259943645\n",
      "Batch: 30 of 91. Loss: 0.1669512838125229. Mean so far: 0.13674478064621648. Mean of 100: 0.13674478064621648\n",
      "Batch: 40 of 91. Loss: 0.13614165782928467. Mean so far: 0.13363190867551944. Mean of 100: 0.13363190867551944\n",
      "Batch: 50 of 91. Loss: 0.1608356237411499. Mean so far: 0.14118289640721152. Mean of 100: 0.14118289640721152\n",
      "Batch: 60 of 91. Loss: 0.1334172785282135. Mean so far: 0.14139592549839958. Mean of 100: 0.14139592549839958\n",
      "Batch: 70 of 91. Loss: 0.05755739286541939. Mean so far: 0.13632552194553363. Mean of 100: 0.13632552194553363\n",
      "Batch: 80 of 91. Loss: 0.09268392622470856. Mean so far: 0.1312416553221367. Mean of 100: 0.1312416553221367\n",
      "Batch: 90 of 91. Loss: 0.10366598516702652. Mean so far: 0.12982217259295695. Mean of 100: 0.12982217259295695\n",
      "Validation loss: 0.12982217259295695. Val measure: 0.6275348704336792\n",
      "Validation loop took 39.22178840637207\n",
      "Current Epoch: 5\n",
      "Eval  Model:  pascal_voc_uni_adv_trained . MAPE:  0.6275348704336792 . Avg loss: 0.12982217259295695\n",
      "Train Model:  pascal_voc_uni_adv_trained . MAPE 0.7600644825113345 Avg loss: 0.10491702374484804\n",
      "Current MAPE:  0.6275348704336792 0.12982217259295695 at epoch 5\n",
      "AP of aeroplane    : 0.8545490583809212\n",
      "AP of bicycle      : 0.6672243059533529\n",
      "AP of bird         : 0.6921190858721128\n",
      "AP of boat         : 0.6727215699807275\n",
      "AP of bottle       : 0.3568227242512688\n",
      "AP of bus          : 0.8540816437334482\n",
      "AP of car          : 0.639400947545783\n",
      "AP of cat          : 0.7094973949180506\n",
      "AP of chair        : 0.5376191659137263\n",
      "AP of cow          : 0.4225013117283584\n",
      "AP of diningtable  : 0.4450377568137277\n",
      "AP of dog          : 0.6044442781878887\n",
      "AP of horse        : 0.5772349702279284\n",
      "AP of motorbike    : 0.7571015399414764\n",
      "AP of person       : 0.8822117965188341\n",
      "AP of pottedplant  : 0.4266953248850367\n",
      "AP of sheep        : 0.5974422992709926\n",
      "AP of sofa         : 0.38760181522897885\n",
      "AP of train        : 0.7996767878623487\n",
      "AP of tvmonitor    : 0.6667136314586197\n",
      "Current Epoch: 6\n",
      "Train Loop:\n",
      "Batch: 0 of 90. Loss: 0.0998808890581131. Mean so far: 0.0998808890581131. Mean of 100: 0.0998808890581131\n",
      "Batch: 10 of 90. Loss: 0.08513577282428741. Mean so far: 0.099132355641235. Mean of 100: 0.099132355641235\n",
      "Batch: 20 of 90. Loss: 0.097006656229496. Mean so far: 0.09853372793822061. Mean of 100: 0.09853372793822061\n",
      "Batch: 30 of 90. Loss: 0.0907919630408287. Mean so far: 0.09947475887114002. Mean of 100: 0.09947475887114002\n",
      "Batch: 40 of 90. Loss: 0.10000655800104141. Mean so far: 0.09935265870355978. Mean of 100: 0.09935265870355978\n",
      "Batch: 50 of 90. Loss: 0.09865055233240128. Mean so far: 0.09934894842844383. Mean of 100: 0.09934894842844383\n",
      "Batch: 60 of 90. Loss: 0.11036930233240128. Mean so far: 0.09949599438514865. Mean of 100: 0.09949599438514865\n",
      "Batch: 70 of 90. Loss: 0.08647932857275009. Mean so far: 0.09837085575285093. Mean of 100: 0.09837085575285093\n",
      "Batch: 80 of 90. Loss: 0.11318459361791611. Mean so far: 0.09861676376542927. Mean of 100: 0.09861676376542927\n",
      "Train loss: 0.09896995524565379. Train measure: 0.788026448509864\n",
      "Train loop took 41.33872103691101\n",
      "Val Loop:\n",
      "Batch: 0 of 91. Loss: 0.10146913677453995. Mean so far: 0.10146913677453995. Mean of 100: 0.10146913677453995\n",
      "Batch: 10 of 91. Loss: 0.1207621619105339. Mean so far: 0.11966196447610855. Mean of 100: 0.11966196447610855\n",
      "Batch: 20 of 91. Loss: 0.16147947311401367. Mean so far: 0.1230766461009071. Mean of 100: 0.1230766461009071\n",
      "Batch: 30 of 91. Loss: 0.1700652837753296. Mean so far: 0.13665881464558263. Mean of 100: 0.13665881464558263\n",
      "Batch: 40 of 91. Loss: 0.1473085731267929. Mean so far: 0.13517214321508642. Mean of 100: 0.13517214321508642\n",
      "Batch: 50 of 91. Loss: 0.1541564017534256. Mean so far: 0.1426179815156787. Mean of 100: 0.1426179815156787\n",
      "Batch: 60 of 91. Loss: 0.12535496056079865. Mean so far: 0.14174900619221514. Mean of 100: 0.14174900619221514\n",
      "Batch: 70 of 91. Loss: 0.05902618169784546. Mean so far: 0.1365454530631992. Mean of 100: 0.1365454530631992\n",
      "Batch: 80 of 91. Loss: 0.09292566031217575. Mean so far: 0.13150355762537616. Mean of 100: 0.13150355762537616\n",
      "Batch: 90 of 91. Loss: 0.09490963816642761. Mean so far: 0.12944793950889136. Mean of 100: 0.12944793950889136\n",
      "Validation loss: 0.12944793950889136. Val measure: 0.6297235737845531\n",
      "Validation loop took 39.03956484794617\n",
      "Current Epoch: 6\n",
      "Eval  Model:  pascal_voc_uni_adv_trained . MAPE:  0.6297235737845531 . Avg loss: 0.12944793950889136\n",
      "Train Model:  pascal_voc_uni_adv_trained . MAPE 0.788026448509864 Avg loss: 0.09896995524565379\n",
      "Current MAPE:  0.6297235737845531 0.12944793950889136 at epoch 6\n",
      "AP of aeroplane    : 0.8564673080894531\n",
      "AP of bicycle      : 0.6670218754080801\n",
      "AP of bird         : 0.6922000657083063\n",
      "AP of boat         : 0.6767295304425048\n",
      "AP of bottle       : 0.36168528076851003\n",
      "AP of bus          : 0.8547026212912021\n",
      "AP of car          : 0.6463472070314918\n",
      "AP of cat          : 0.7104997611508092\n",
      "AP of chair        : 0.5380202484162953\n",
      "AP of cow          : 0.42476360194312895\n",
      "AP of diningtable  : 0.44923010742753156\n",
      "AP of dog          : 0.6082878721840581\n",
      "AP of horse        : 0.5776285758612866\n",
      "AP of motorbike    : 0.7584122985426559\n",
      "AP of person       : 0.8839413085200937\n",
      "AP of pottedplant  : 0.42716055400452047\n",
      "AP of sheep        : 0.5966850939541255\n",
      "AP of sofa         : 0.3929025585731647\n",
      "AP of train        : 0.8033593122836273\n",
      "AP of tvmonitor    : 0.6684262940902176\n",
      "Current Epoch: 7\n",
      "Train Loop:\n",
      "Batch: 0 of 90. Loss: 0.09357685595750809. Mean so far: 0.09357685595750809. Mean of 100: 0.09357685595750809\n",
      "Batch: 10 of 90. Loss: 0.10105603188276291. Mean so far: 0.09774448587135835. Mean of 100: 0.09774448587135835\n",
      "Batch: 20 of 90. Loss: 0.10260670632123947. Mean so far: 0.09659549700362342. Mean of 100: 0.09659549700362342\n",
      "Batch: 30 of 90. Loss: 0.10025941580533981. Mean so far: 0.09531017561112681. Mean of 100: 0.09531017561112681\n",
      "Batch: 40 of 90. Loss: 0.08596914261579514. Mean so far: 0.09607354587898022. Mean of 100: 0.09607354587898022\n",
      "Batch: 50 of 90. Loss: 0.10666191577911377. Mean so far: 0.096963309628122. Mean of 100: 0.096963309628122\n",
      "Batch: 60 of 90. Loss: 0.09337933361530304. Mean so far: 0.09613369527410288. Mean of 100: 0.09613369527410288\n",
      "Batch: 70 of 90. Loss: 0.08894594013690948. Mean so far: 0.0962816524043889. Mean of 100: 0.0962816524043889\n",
      "Batch: 80 of 90. Loss: 0.08571552485227585. Mean so far: 0.09706065086302934. Mean of 100: 0.09706065086302934\n",
      "Train loss: 0.09720809178219901. Train measure: 0.7967578009331245\n",
      "Train loop took 41.265610694885254\n",
      "Val Loop:\n",
      "Batch: 0 of 91. Loss: 0.10772090405225754. Mean so far: 0.10772090405225754. Mean of 100: 0.10772090405225754\n",
      "Batch: 10 of 91. Loss: 0.12522678077220917. Mean so far: 0.12194797396659851. Mean of 100: 0.12194797396659851\n",
      "Batch: 20 of 91. Loss: 0.15564753115177155. Mean so far: 0.12335723922366187. Mean of 100: 0.12335723922366187\n",
      "Batch: 30 of 91. Loss: 0.16897156834602356. Mean so far: 0.13684581556627828. Mean of 100: 0.13684581556627828\n",
      "Batch: 40 of 91. Loss: 0.14767219126224518. Mean so far: 0.1356217059783819. Mean of 100: 0.1356217059783819\n",
      "Batch: 50 of 91. Loss: 0.15739330649375916. Mean so far: 0.14276901428021638. Mean of 100: 0.14276901428021638\n",
      "Batch: 60 of 91. Loss: 0.12592045962810516. Mean so far: 0.14190591590814902. Mean of 100: 0.14190591590814902\n",
      "Batch: 70 of 91. Loss: 0.057396817952394485. Mean so far: 0.13658430348609535. Mean of 100: 0.13658430348609535\n",
      "Batch: 80 of 91. Loss: 0.09179438650608063. Mean so far: 0.13131491577735654. Mean of 100: 0.13131491577735654\n",
      "Batch: 90 of 91. Loss: 0.09958691149950027. Mean so far: 0.12969529980814065. Mean of 100: 0.12969529980814065\n",
      "Validation loss: 0.12969529980814065. Val measure: 0.6305596778248597\n",
      "Validation loop took 39.09636640548706\n",
      "Current Epoch: 7\n",
      "Eval  Model:  pascal_voc_uni_adv_trained . MAPE:  0.6305596778248597 . Avg loss: 0.12969529980814065\n",
      "Train Model:  pascal_voc_uni_adv_trained . MAPE 0.7967578009331245 Avg loss: 0.09720809178219901\n",
      "Current MAPE:  0.6305596778248597 0.12969529980814065 at epoch 7\n",
      "AP of aeroplane    : 0.8567430812962976\n",
      "AP of bicycle      : 0.6692402648620569\n",
      "AP of bird         : 0.6946977912691583\n",
      "AP of boat         : 0.6741099804255644\n",
      "AP of bottle       : 0.36517743812454656\n",
      "AP of bus          : 0.8536927608306928\n",
      "AP of car          : 0.6466347408769875\n",
      "AP of cat          : 0.7102689363879693\n",
      "AP of chair        : 0.5401024634797483\n",
      "AP of cow          : 0.42303520408696543\n",
      "AP of diningtable  : 0.4504933488330326\n",
      "AP of dog          : 0.6085774690285322\n",
      "AP of horse        : 0.5859718319277502\n",
      "AP of motorbike    : 0.7604225888257155\n",
      "AP of person       : 0.885059967561862\n",
      "AP of pottedplant  : 0.43025468072612616\n",
      "AP of sheep        : 0.5905574990282196\n",
      "AP of sofa         : 0.39582926487429476\n",
      "AP of train        : 0.8014057904353507\n",
      "AP of tvmonitor    : 0.6689184536163248\n",
      "Current Epoch: 8\n",
      "Train Loop:\n",
      "Batch: 0 of 90. Loss: 0.10000365972518921. Mean so far: 0.10000365972518921. Mean of 100: 0.10000365972518921\n",
      "Batch: 10 of 90. Loss: 0.1096985712647438. Mean so far: 0.09868078678846359. Mean of 100: 0.09868078678846359\n",
      "Batch: 20 of 90. Loss: 0.09235191345214844. Mean so far: 0.09805964146341596. Mean of 100: 0.09805964146341596\n",
      "Batch: 30 of 90. Loss: 0.09012551605701447. Mean so far: 0.09763003068585549. Mean of 100: 0.09763003068585549\n",
      "Batch: 40 of 90. Loss: 0.09891289472579956. Mean so far: 0.09879735948109045. Mean of 100: 0.09879735948109045\n",
      "Batch: 50 of 90. Loss: 0.09943392127752304. Mean so far: 0.09881100087773566. Mean of 100: 0.09881100087773566\n",
      "Batch: 60 of 90. Loss: 0.09768739342689514. Mean so far: 0.09850689451225468. Mean of 100: 0.09850689451225468\n",
      "Batch: 70 of 90. Loss: 0.08091719448566437. Mean so far: 0.09791469878294098. Mean of 100: 0.09791469878294098\n",
      "Batch: 80 of 90. Loss: 0.10326547920703888. Mean so far: 0.09777488743449435. Mean of 100: 0.09777488743449435\n",
      "Train loss: 0.09779686099953122. Train measure: 0.7912189677769497\n",
      "Train loop took 41.448906898498535\n",
      "Val Loop:\n",
      "Batch: 0 of 91. Loss: 0.10504744201898575. Mean so far: 0.10504744201898575. Mean of 100: 0.10504744201898575\n",
      "Batch: 10 of 91. Loss: 0.12514109909534454. Mean so far: 0.12031939625740051. Mean of 100: 0.12031939625740051\n",
      "Batch: 20 of 91. Loss: 0.1592165231704712. Mean so far: 0.12351869649830319. Mean of 100: 0.12351869649830319\n",
      "Batch: 30 of 91. Loss: 0.16973444819450378. Mean so far: 0.13637706517211853. Mean of 100: 0.13637706517211853\n",
      "Batch: 40 of 91. Loss: 0.14766626060009003. Mean so far: 0.13510831627177028. Mean of 100: 0.13510831627177028\n",
      "Batch: 50 of 91. Loss: 0.1483946591615677. Mean so far: 0.1419988857472644. Mean of 100: 0.1419988857472644\n",
      "Batch: 60 of 91. Loss: 0.11975907534360886. Mean so far: 0.14042518006973578. Mean of 100: 0.14042518006973578\n",
      "Batch: 70 of 91. Loss: 0.05943899229168892. Mean so far: 0.13574443227598365. Mean of 100: 0.13574443227598365\n",
      "Batch: 80 of 91. Loss: 0.0948050245642662. Mean so far: 0.13098458876764332. Mean of 100: 0.13098458876764332\n",
      "Batch: 90 of 91. Loss: 0.09988109022378922. Mean so far: 0.12929270805402115. Mean of 100: 0.12929270805402115\n",
      "Validation loss: 0.12929270805402115. Val measure: 0.631327421254775\n",
      "Validation loop took 39.10330128669739\n",
      "Current Epoch: 8\n",
      "Eval  Model:  pascal_voc_uni_adv_trained . MAPE:  0.631327421254775 . Avg loss: 0.12929270805402115\n",
      "Train Model:  pascal_voc_uni_adv_trained . MAPE 0.7912189677769497 Avg loss: 0.09779686099953122\n",
      "Current MAPE:  0.631327421254775 0.12929270805402115 at epoch 8\n",
      "AP of aeroplane    : 0.8577981905794072\n",
      "AP of bicycle      : 0.6681803568213458\n",
      "AP of bird         : 0.6976853226169145\n",
      "AP of boat         : 0.6764317855240389\n",
      "AP of bottle       : 0.36384704198366286\n",
      "AP of bus          : 0.8532200011374947\n",
      "AP of car          : 0.643490168937541\n",
      "AP of cat          : 0.7103380711439082\n",
      "AP of chair        : 0.5393681100737243\n",
      "AP of cow          : 0.43052761496583136\n",
      "AP of diningtable  : 0.44955330762741297\n",
      "AP of dog          : 0.6115906178812633\n",
      "AP of horse        : 0.5907991092609627\n",
      "AP of motorbike    : 0.756991493021684\n",
      "AP of person       : 0.8847439703493145\n",
      "AP of pottedplant  : 0.42942505135444226\n",
      "AP of sheep        : 0.5929692304125126\n",
      "AP of sofa         : 0.3960630016414127\n",
      "AP of train        : 0.8035091704540874\n",
      "AP of tvmonitor    : 0.6700168093085388\n",
      "Current Epoch: 9\n",
      "Train Loop:\n",
      "Batch: 0 of 90. Loss: 0.07714735716581345. Mean so far: 0.07714735716581345. Mean of 100: 0.07714735716581345\n",
      "Batch: 10 of 90. Loss: 0.09936482459306717. Mean so far: 0.09951868111437018. Mean of 100: 0.09951868111437018\n",
      "Batch: 20 of 90. Loss: 0.08215288072824478. Mean so far: 0.0989664186324392. Mean of 100: 0.0989664186324392\n",
      "Batch: 30 of 90. Loss: 0.10294508188962936. Mean so far: 0.09941022891190744. Mean of 100: 0.09941022891190744\n",
      "Batch: 40 of 90. Loss: 0.10034900158643723. Mean so far: 0.09880159504529906. Mean of 100: 0.09880159504529906\n",
      "Batch: 50 of 90. Loss: 0.09732171148061752. Mean so far: 0.09772299273925669. Mean of 100: 0.09772299273925669\n",
      "Batch: 60 of 90. Loss: 0.10033612698316574. Mean so far: 0.09739415359790207. Mean of 100: 0.09739415359790207\n",
      "Batch: 70 of 90. Loss: 0.0818374827504158. Mean so far: 0.09724550075094465. Mean of 100: 0.09724550075094465\n",
      "Batch: 80 of 90. Loss: 0.10081764310598373. Mean so far: 0.09724624638940081. Mean of 100: 0.09724624638940081\n",
      "Train loss: 0.09735158665312661. Train measure: 0.7973992768057211\n",
      "Train loop took 41.441667318344116\n",
      "Val Loop:\n",
      "Batch: 0 of 91. Loss: 0.10001438856124878. Mean so far: 0.10001438856124878. Mean of 100: 0.10001438856124878\n",
      "Batch: 10 of 91. Loss: 0.12133226543664932. Mean so far: 0.11891992661085996. Mean of 100: 0.11891992661085996\n",
      "Batch: 20 of 91. Loss: 0.1585908681154251. Mean so far: 0.12116461779390063. Mean of 100: 0.12116461779390063\n",
      "Batch: 30 of 91. Loss: 0.1592080295085907. Mean so far: 0.13402260503461283. Mean of 100: 0.13402260503461283\n",
      "Batch: 40 of 91. Loss: 0.15228235721588135. Mean so far: 0.13328338759701427. Mean of 100: 0.13328338759701427\n",
      "Batch: 50 of 91. Loss: 0.15847092866897583. Mean so far: 0.14191221927895264. Mean of 100: 0.14191221927895264\n",
      "Batch: 60 of 91. Loss: 0.11694826185703278. Mean so far: 0.14010559046854737. Mean of 100: 0.14010559046854737\n",
      "Batch: 70 of 91. Loss: 0.05858331546187401. Mean so far: 0.13504799261269435. Mean of 100: 0.13504799261269435\n",
      "Batch: 80 of 91. Loss: 0.0941983088850975. Mean so far: 0.13016885174093423. Mean of 100: 0.13016885174093423\n",
      "Batch: 90 of 91. Loss: 0.09759709239006042. Mean so far: 0.12882994414194598. Mean of 100: 0.12882994414194598\n",
      "Validation loss: 0.12882994414194598. Val measure: 0.6327189349849617\n",
      "Validation loop took 39.247995138168335\n",
      "Current Epoch: 9\n",
      "Eval  Model:  pascal_voc_uni_adv_trained . MAPE:  0.6327189349849617 . Avg loss: 0.12882994414194598\n",
      "Train Model:  pascal_voc_uni_adv_trained . MAPE 0.7973992768057211 Avg loss: 0.09735158665312661\n",
      "Current MAPE:  0.6327189349849617 0.12882994414194598 at epoch 9\n",
      "AP of aeroplane    : 0.858373626500215\n",
      "AP of bicycle      : 0.6693783127948368\n",
      "AP of bird         : 0.6999091382361301\n",
      "AP of boat         : 0.677199188301701\n",
      "AP of bottle       : 0.36352479537057864\n",
      "AP of bus          : 0.8546003042394363\n",
      "AP of car          : 0.6526354819991089\n",
      "AP of cat          : 0.7144151743525413\n",
      "AP of chair        : 0.5385576634709442\n",
      "AP of cow          : 0.4268731350531586\n",
      "AP of diningtable  : 0.4501152921016677\n",
      "AP of dog          : 0.6127068389978793\n",
      "AP of horse        : 0.5903207179476737\n",
      "AP of motorbike    : 0.7599698575018953\n",
      "AP of person       : 0.8857673785015138\n",
      "AP of pottedplant  : 0.4298066234102207\n",
      "AP of sheep        : 0.5914035919723322\n",
      "AP of sofa         : 0.3994795036139925\n",
      "AP of train        : 0.8065396706599451\n",
      "AP of tvmonitor    : 0.6728024046734616\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'trainer_fine_tune' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7083/3057584451.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Losses:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainer_fine_tune\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracies:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainer_fine_tune\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch_mape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trainer_fine_tune' is not defined"
     ]
    }
   ],
   "source": [
    "seed_everything()\n",
    "root_dir = 'Data/PascalVOC/VOCdevkit/VOC2012'\n",
    "\n",
    "config = {\n",
    "    'lr': 0.0001,\n",
    "    'batch_size': 64,\n",
    "    'weight_decay': 0.01\n",
    "}\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_path = 'models/pascal_voc_resnet_fine_tuned.pt'\n",
    "\n",
    "# Fine-tune all layers\n",
    "resnet, loaded_state_dict = load_model(model_path = model_path)\n",
    "\n",
    "for name, param in resnet.named_parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "dataloaders, classes = prepare_dataloaders_pascal_voc(root_dir, batch_size = config['batch_size'], smaller_resize = True)\n",
    "\n",
    "loss_fn = nn.BCEWithLogitsLoss(weight=None, reduction='mean')\n",
    "\n",
    "train_params = [p for p in resnet.parameters() if p.requires_grad]\n",
    "\n",
    "optimizer = torch.optim.Adam(train_params, lr = config['lr'], weight_decay = config['weight_decay'])\n",
    "#scheduler = CustomScheduler(optimizer)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[4,6], gamma=0.1)\n",
    "\n",
    "training_params = {\n",
    "    'dataloaders': dataloaders,\n",
    "    'optimizer': optimizer,\n",
    "    'scheduler': scheduler\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "vec = torch.load('models/uni_pert_pascal_voc.pt')\n",
    "attack = UniversalAttack(vec)\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model = resnet,\n",
    "    loss_fn = loss_fn,\n",
    "    classes = classes,\n",
    "    num_epochs = 10,\n",
    "    model_name = f'pascal_voc_uni_adv_trained',\n",
    "    training_params = training_params,\n",
    "    multi_label = True,\n",
    "    print_frequency = 10,\n",
    "    adversarial_training = True,\n",
    "    adversarial_attack = attack,\n",
    "    custom_scheduler = False\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "\n",
    "print(\"Losses:\",trainer_fine_tune.epoch_loss)\n",
    "print(\"Accuracies:\",trainer_fine_tune.epoch_mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049549b7-b987-4bc8-8522-0b839abcd68e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
