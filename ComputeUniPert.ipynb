{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "377b4b1c-2ca3-41d7-a1be-b53aad4e372f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded models/pascal_voc_resnet_fine_tuned.pt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import PIL.Image\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "\n",
    "from src.data.PascalVOC import dataset_voc, prepare_dataloaders_pascal_voc\n",
    "from src.attacks.attacks import FastGradientSign, ProjectedGradientDescent, UniversalPerturbation\n",
    "from src.training.Trainer import Trainer\n",
    "\n",
    "def load_model(num_classes = 20, model_path = None, to_cuda = True):\n",
    "    if not model_path:\n",
    "        model = torchvision.models.resnet18(pretrained = True)\n",
    "        input_feat = model.fc.in_features\n",
    "        \n",
    "        model.fc = nn.Linear(input_feat, num_classes)\n",
    "        model.fc.reset_parameters()\n",
    "        loaded_state_dict = False\n",
    "    \n",
    "    else:\n",
    "        print(\"Loaded\", model_path)\n",
    "        model = torchvision.models.resnet18()\n",
    "        input_feat = model.fc.in_features\n",
    "        model.fc = nn.Linear(input_feat, num_classes)\n",
    "        loaded_model = torch.load(model_path)\n",
    "        model.load_state_dict(loaded_model['model_state_dict'])\n",
    "        loaded_state_dict = True\n",
    "        \n",
    "    if to_cuda:\n",
    "        model = model.to('cuda')\n",
    "        \n",
    "    return model, loaded_state_dict\n",
    "\n",
    "\n",
    "root_dir = 'Data/PascalVOC/VOCdevkit/VOC2012'\n",
    "\n",
    "resnet, loaded_state_dict = load_model(model_path = 'models/pascal_voc_resnet_fine_tuned.pt')\n",
    "\n",
    "dataloaders, classes = prepare_dataloaders_pascal_voc(root_dir, batch_size = 500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71bb43b4-e038-4d31-90d0-853792a87ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCEWithLogitsLoss(weight=None, reduction='mean')\n",
    "\n",
    "up = UniversalPerturbation(resnet, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd2ea15f-7801-4c90-80bb-9ee7cd42660b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for samp in dataloaders['train']:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af8b6d2e-d7ab-418d-baf3-b194ca000ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = samp['image'].to('cuda')\n",
    "label = samp['label'].to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e978a225-e646-467f-ae5f-89f320da91dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs torch.Size([500, 3, 224, 224])\n",
      "predictions:  torch.Size([500, 20])\n",
      "targets torch.Size([500, 20])\n",
      "fool_rate 0.0189\n",
      "0\n",
      "predictions:  torch.Size([500, 20])\n",
      "targets torch.Size([500, 20])\n",
      "fool_rate 0.0253\n",
      "1\n",
      "predictions:  torch.Size([500, 20])\n",
      "targets torch.Size([500, 20])\n",
      "fool_rate 0.0342\n",
      "2\n",
      "predictions:  torch.Size([500, 20])\n",
      "targets torch.Size([500, 20])\n",
      "fool_rate 0.0442\n",
      "3\n",
      "predictions:  torch.Size([500, 20])\n",
      "targets torch.Size([500, 20])\n",
      "fool_rate 0.0513\n",
      "4\n",
      "predictions:  torch.Size([500, 20])\n",
      "targets torch.Size([500, 20])\n",
      "fool_rate 0.0573\n"
     ]
    }
   ],
   "source": [
    "v = up.compute_perturbation(inputs = img, targets = label, max_iter = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8e95b11-d750-4a89-9225-08637a55c7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(v, 'models/uni_pert_pascal_voc.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2b822f-e6fa-40d5-a613-7baff60008f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f47d51-9d1d-4385-a7d1-84af963295fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de69597-1d8e-4499-84b3-592a173fb3ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5f0b7c-880a-48c5-9683-cb4b41ac551c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "15fd2562-e14a-4dbb-a890-c52d00abf137",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_correct_label(pred, label, total_present):\n",
    "    num_correct = 0\n",
    "    \n",
    "    for p,l in zip(pred.squeeze(), label.squeeze()):\n",
    "        if l == 1 and p == l:\n",
    "            num_correct += 1\n",
    "            \n",
    "    return num_correct > 0\n",
    "\n",
    "def deepfool_multi_label(image, label, net, num_classes, overshoot, max_iter):\n",
    "    \n",
    "    out = net(image).data.cpu().flatten(start_dim=1)\n",
    "    pred = out.sigmoid()\n",
    "    pred = pred > 0.5\n",
    "    \n",
    "    input_shape = image.shape\n",
    "    pert_image = image.clone()\n",
    "    \n",
    "    w = np.zeros(input_shape)\n",
    "    r_tot = np.zeros(input_shape)\n",
    "    \n",
    "    loop_i = 0\n",
    "    \n",
    "    x = pert_image\n",
    "    x.requires_grad = True\n",
    "    fs = net(x)\n",
    "    k_i = label\n",
    "    \n",
    "#    batch_size = x.shape[0]\n",
    "    \n",
    "    corrects = torch.nonzero(label.squeeze())\n",
    "    num_correct = label.count_nonzero()\n",
    "    while check_if_correct_label(k_i, label, num_correct) and loop_i < max_iter:\n",
    "        \n",
    "        \"\"\"\n",
    "        keep_samples = [] \n",
    "        for b in range(batch_size):\n",
    "            # Simplify to only consider if all classes are correct.\n",
    "            if (k_i[b] == label[b]).all():\n",
    "                keep_samples.append(b)\n",
    "\n",
    "        k_i = k_i[keep_samples, :]\n",
    "        print(k_i)\n",
    "        \"\"\"\n",
    "        \n",
    "        pert = torch.inf\n",
    "        # Only want gradients for true class\n",
    "        masked_output = fs * label\n",
    "        masked_output.sum().backward(retain_graph=True)\n",
    "        grad_orig = x.grad.data.cpu().numpy().copy()\n",
    "        \n",
    "        for corr in corrects:\n",
    "            for k in range(1, num_classes):\n",
    "                if k in corrects:\n",
    "                    continue\n",
    "                x.grad.zero_()\n",
    "                fs[:,k].sum().backward(retain_graph=True)\n",
    "                cur_grad = x.grad.data.cpu().numpy().copy()\n",
    "\n",
    "                w_k = cur_grad - grad_orig\n",
    "                f_k = (fs[0, k] \n",
    "                       - fs[0, corr]).data.cpu().numpy()\n",
    "\n",
    "                pert_k = abs(f_k) / np.linalg.norm(w_k.flatten())\n",
    "\n",
    "                # determine which w_k to use\n",
    "                if pert_k < pert:\n",
    "                    pert = pert_k\n",
    "                    w = w_k\n",
    "        \n",
    "        \n",
    "        r_i =  (pert+1e-4) * w / np.linalg.norm(w)\n",
    "        r_tot = np.float32(r_tot + r_i)\n",
    "        pert_image = image + (1+overshoot)*torch.from_numpy(r_tot).cuda()\n",
    "        \n",
    "        x = pert_image\n",
    "        x.requires_grad = True\n",
    "        fs = net(x)\n",
    "        out = net(image).data.cpu().flatten(start_dim=1)\n",
    "        pred = out.sigmoid()\n",
    "        k_i = (pred > 0.5).cuda()\n",
    "        \n",
    "        loop_i += 1\n",
    "    \n",
    "    return (1+overshoot)*r_tot, loop_i, label, k_i, pert_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "d02c738a-ad84-46cb-8b50-90c4ceeae71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in dataloaders['val']:\n",
    "    img = b['image'].to('cuda')\n",
    "    label = b['label'].to('cuda')\n",
    "    aaa = deepfool_vectorized(img, label, resnet, 20, 99999, 0.1)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "fc7fe411-dafe-44a9-bc11-fca5e7c190c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.5253, -0.5424, -0.5424,  ..., -0.5767, -0.5596, -0.5424],\n",
       "          [-0.5253, -0.5253, -0.5424,  ..., -0.5767, -0.5767, -0.5767],\n",
       "          [-0.5253, -0.5253, -0.5424,  ..., -0.5424, -0.5596, -0.5596],\n",
       "          ...,\n",
       "          [ 0.2624,  0.2282,  0.2624,  ...,  1.1015,  1.2043,  1.2385],\n",
       "          [ 0.0569,  0.0912,  0.0741,  ...,  0.6392,  0.8447,  0.7419],\n",
       "          [ 0.0912,  0.0741,  0.0741,  ...,  0.1254,  0.2967,  0.2282]],\n",
       "\n",
       "         [[ 0.3452,  0.3277,  0.3277,  ...,  0.2927,  0.3102,  0.3277],\n",
       "          [ 0.3452,  0.3452,  0.3277,  ...,  0.2927,  0.2927,  0.2927],\n",
       "          [ 0.3452,  0.3452,  0.3277,  ...,  0.3277,  0.3102,  0.3102],\n",
       "          ...,\n",
       "          [ 0.3803,  0.3452,  0.3803,  ..., -0.7577, -0.7227, -0.9153],\n",
       "          [ 0.1702,  0.2052,  0.1877,  ..., -0.4776, -0.5651, -0.5826],\n",
       "          [ 0.2052,  0.1877,  0.1877,  ...,  0.2402,  0.4328,  0.2577]],\n",
       "\n",
       "         [[ 1.3154,  1.2980,  1.2980,  ...,  1.2631,  1.2805,  1.2980],\n",
       "          [ 1.3154,  1.3154,  1.2980,  ...,  1.2631,  1.2631,  1.2631],\n",
       "          [ 1.3154,  1.3154,  1.2980,  ...,  1.2980,  1.2805,  1.2805],\n",
       "          ...,\n",
       "          [ 0.5311,  0.4962,  0.5311,  ..., -0.5670, -0.5147, -0.7238],\n",
       "          [ 0.3219,  0.3568,  0.3393,  ..., -0.3230, -0.3927, -0.4450],\n",
       "          [ 0.3568,  0.3393,  0.3393,  ...,  0.3742,  0.5659,  0.4614]]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "d82eb408-bb54-4a78-8de4-e835dd1495cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.3546e+00, -3.5689e+00, -3.7673e+00,  ...,  2.6930e+00,\n",
       "            2.2496e+01, -1.5855e+00],\n",
       "          [-2.6241e+00, -5.6123e+00, -3.2453e+00,  ..., -4.8435e-01,\n",
       "           -1.7105e+01,  1.1913e+01],\n",
       "          [-3.4484e+00,  7.0395e+00, -9.5840e-01,  ...,  1.9994e+01,\n",
       "            2.5080e+01, -1.0923e+01],\n",
       "          ...,\n",
       "          [ 6.2674e-01,  1.3454e+00,  3.0065e-01,  ..., -6.7737e-01,\n",
       "            1.0598e-01,  1.4600e+00],\n",
       "          [ 8.6688e-01, -2.3384e-01,  4.8277e-01,  ..., -1.2251e+00,\n",
       "           -5.0553e-01,  1.4650e+00],\n",
       "          [ 7.1823e-01,  3.4597e-01,  1.0841e+00,  ...,  4.3642e-01,\n",
       "           -2.0073e+00,  1.0292e+00]],\n",
       "\n",
       "         [[ 3.1952e+00, -3.4858e+00, -4.3830e+00,  ..., -3.4517e+00,\n",
       "            1.0696e+01, -2.0841e+01],\n",
       "          [-2.6695e+00, -6.2821e+00, -6.2855e+00,  ..., -3.9940e+00,\n",
       "           -3.9600e+01, -1.3214e+01],\n",
       "          [-2.9644e+00,  1.0116e+01, -4.2306e+00,  ...,  3.0408e+01,\n",
       "            2.7284e+01, -2.7261e+01],\n",
       "          ...,\n",
       "          [ 1.7374e+00,  1.2765e-02, -5.7343e+00,  ..., -3.2517e+00,\n",
       "           -1.4567e+00,  4.9972e-01],\n",
       "          [ 1.3952e+00, -1.6151e+00, -3.8170e+00,  ..., -3.1502e+00,\n",
       "           -1.8501e+00,  1.1351e+00],\n",
       "          [ 1.1119e+00, -3.0088e-01, -1.0740e+00,  ..., -1.4844e-01,\n",
       "           -2.9066e+00,  1.3399e+00]],\n",
       "\n",
       "         [[ 4.4990e+00,  1.0385e+00,  5.9381e-01,  ..., -3.0163e+00,\n",
       "            5.9134e+00, -1.6932e+01],\n",
       "          [ 9.2617e-01, -6.2967e-01,  6.2975e-01,  ..., -7.6896e+00,\n",
       "           -2.9919e+01, -8.8233e+00],\n",
       "          [ 2.6718e-01,  9.3771e+00,  2.0674e+00,  ...,  1.1633e+01,\n",
       "            1.3657e+01, -1.3932e+01],\n",
       "          ...,\n",
       "          [ 2.1917e+00,  3.1712e+00,  1.5795e+00,  ...,  2.4350e-01,\n",
       "            1.0362e+00,  9.9603e-01],\n",
       "          [ 1.7694e+00,  1.2843e+00,  1.5637e+00,  ..., -1.2335e+00,\n",
       "            2.1641e-01,  1.4722e+00],\n",
       "          [ 1.4360e+00,  1.5358e+00,  2.1800e+00,  ...,  2.2092e-01,\n",
       "           -8.2277e-01,  1.8772e+00]]]], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aaa[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "83000428-8d7d-49d7-b89d-d3f71412816c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = os.path.join(os.path.abspath(\"\"),\"src/data/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "885d01f0-2bb3-479d-8427-68466325d136",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torchvision.datasets.MNIST(root=DATA_FOLDER, \n",
    "    train=False,download=True, transform=torchvision.transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "33dd61ff-1cd4-4b57-946f-12234c469323",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "226b2ac6-3f37-4ebd-96d1-03ed74267724",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in dataloader:\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
